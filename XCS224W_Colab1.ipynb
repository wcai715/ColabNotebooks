{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wcai715/ColabNotebooks/blob/main/XCS224W_Colab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Colab 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this Colab, you will write a pipeline for **learning node embeddings** in a graph. You will go through the following 3 steps:\n",
        "\n",
        "1.   To start, you will load the familiar [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) from Colab 0. You will explore multiple graph statistics over this graph.\n",
        "2.   You will then work to transform the graph structure into a PyTorch tensor so that you can perform machine learning over the graph.\n",
        "\n",
        "3. Finally, you will write your first graph learning algorithm: a node embedding model. For simplicity, your model is simpler than the DeepWalk and node2vec algorithms taught in Module 1, Unit 1.2 - Node Embeddings. Nevertheless, it will still be rewarding and challenging, as you will write the whole procedure from scratch via PyTorch.\n",
        "\n",
        "Let's get started!\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells** so that the intermediate variables / packages will carry over to the next cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvduTt3oKimg"
      },
      "source": [
        "## Building + Debugging Notes\n",
        "While working through this Colab and future Colabs, we strongly encourage you to follow a couple of building / debugging strategies:\n",
        "- During debugging make sure to run your notebook using the CPU runtime. You can change the notebook runtime by selecting `Runtime` and then `Change runtime type`. From the dropdown, select `None` as the `hardware accelerator`.\n",
        "- When working with PyTorch and Neural Network models, understanding the shapes of different tensors, especially the input and output tensors is incredibly helpful.\n",
        "- When training models, it is helpful to start by only running 1 epoch or even just a couple of batch iterations. This way you can check that all your tensor shapes and logic match up, while also tracking expected behavior, such as a decreasing training loss. Remember to comment out / save the default number of epochs that we provide you.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1) Graph Basics\n",
        "To start, load the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club), a classical graph in network science. As discussed in the introduction, you will begin by exploring multiple graph statistics for this graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDkpByYYfSzb"
      },
      "source": [
        "## Setup\n",
        "As introduced in Colab 0, NetworkX is a powerful package for storing and manipluating graphs. We will heavily rely on NetworkX throughout this Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWPkJjPAfVNW"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqUnYT5qUZYh"
      },
      "source": [
        "## Zachary's karate club network\n",
        "\n",
        "The [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) is a social network graph of 34 members of a karate club, where links exist between members who have interacted outside the club."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIETqEfrfy5Y"
      },
      "outputs": [],
      "source": [
        "G = nx.karate_club_graph()\n",
        "\n",
        "# G is an undirected graph\n",
        "type(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDvf3nm-ors4"
      },
      "outputs": [],
      "source": [
        "# Visualize the graph\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  nx.draw(G, with_labels = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX25Y1CrYmgN"
      },
      "source": [
        "## Question 1: What is the average degree of the karate club network? (1 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUhES1VYo3tB"
      },
      "outputs": [],
      "source": [
        "def average_degree(num_edges, num_nodes):\n",
        "  # TODO: Implement a function that takes the number of edges\n",
        "  # and number of nodes of a graph and returns the average node degree of \n",
        "  # the graph. Round the result to nearest integer (for example \n",
        "  # 3.3 will be rounded to 3 and 3.7 will be rounded to 4).\n",
        "\n",
        "  avg_degree = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: Do not import any other Python package\n",
        "  ## 2: Do not use any function from NetworkX\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return avg_degree\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  num_edges = G.number_of_edges()\n",
        "  num_nodes = G.number_of_nodes()\n",
        "  avg_degree = average_degree(num_edges, num_nodes)\n",
        "  print(\"Average degree of karate club network is {}\".format(avg_degree))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk02fD4vYmZI"
      },
      "source": [
        "## Question 2: What is the average clustering coefficient of the karate club network? (1 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k15XKEto1aYJ"
      },
      "outputs": [],
      "source": [
        "def average_clustering_coefficient(G):\n",
        "  # TODO: Implement a function that takes a nx.Graph\n",
        "  # and returns the average clustering coefficient. Round \n",
        "  # the result to 2 decimal places (for example 3.333 will\n",
        "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
        "\n",
        "  avg_cluster_coef = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: Please use the appropriate NetworkX clustering function\n",
        "  ## https://networkx.org/documentation/stable/reference/algorithms/clustering.html\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return avg_cluster_coef\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  avg_cluster_coef = average_clustering_coefficient(G)\n",
        "  print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zghQ-AhXYmP4"
      },
      "source": [
        "## Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)\n",
        "\n",
        "Please complete the code block by implementing the PageRank equation: $r_j^{t+1} = [\\sum_{i \\rightarrow j} \\beta \\frac{r_i^t}{d_i}] + (1 - \\beta) \\frac{1}{N}$ to update the PageRank value of an arbitrary node j for the first time step $t = 0 \\rightarrow t = 1$.\n",
        "\n",
        "**NOTE:** $r_j^0 = 1 / |G|$ for all nodes j (where $|G|$ is the number of nodes in the graph). Namely, at $t=0$ every node is initialized with the same PageRank value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOGdWjNc6O7x"
      },
      "outputs": [],
      "source": [
        "def one_iter_pagerank(G, beta, r0, node_id):\n",
        "  # TODO: Implement a function that takes as input a nx.Graph, beta, r0 \n",
        "  # and node_id. Then for the given node_id = j, compute rj_1 as \n",
        "  # the PageRank of the input node j at time t = 1 (i.e. after ONE iteration). \n",
        "  # \n",
        "  # Round the result to 2 decimal places (for example 3.333 will\n",
        "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
        "  #\n",
        "  # NOTE: rj_0 = r0 for every node j (i.e. each node is initialized with \n",
        "  # the same PageRank value at t = 0; thus we do not need an initial PageRank\n",
        "  # vector r).\n",
        "\n",
        "  rj_1 = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: You should not use nx.pagerank!\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return rj_1\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  beta = 0.8\n",
        "  r0 = 1 / G.number_of_nodes()\n",
        "  node = 0\n",
        "  r0_1 = one_iter_pagerank(G, beta, r0, node)\n",
        "  print(\"The PageRank value for node 0 after one iteration is {}\".format(r0_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icTcOULeYmIu"
      },
      "source": [
        "## Question 4: What is the (raw) closeness centrality for the node with id=5 in the karate club network? (1 Points)\n",
        "\n",
        "The equation for closeness centrality is $c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v}$. Remember that we want the raw (unnormalized) closeness centrality from Module 1, Unit 1.1 - Traditional Feature Based Methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbCsq_tl-3ok"
      },
      "outputs": [],
      "source": [
        "def closeness_centrality(G, node=5):\n",
        "  # TODO: Implement a function that calculates closeness centrality \n",
        "  # for a node in the karate club network. G is the input karate club \n",
        "  # network and 'node' is the node id of the node that we are interested\n",
        "  # in. Please round the closeness centrality result to 2 decimal places.\n",
        "\n",
        "  closeness = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note:\n",
        "  ## 1: You can use networkx closeness centrality function.\n",
        "  ## 2: Notice that networkx closeness centrality returns the normalized \n",
        "  ## closeness directly, which is different from the raw (unnormalized) \n",
        "  ## one that we learned in the lecture.\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return closeness\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  node = 5\n",
        "  closeness = closeness_centrality(G, node=node)\n",
        "  print(\"The karate club network has closeness centrality {}\".format(closeness))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MxvowibYl4x"
      },
      "source": [
        "# 2) Graph to Tensor\n",
        "Now, you will work to transform the graph $G$ into a PyTorch tensor, so that you can perform machine learning over the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDA8PosrA-9V"
      },
      "source": [
        "## Setup\n",
        "Check if PyTorch is properly installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntuPVat_BAf1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fko_2wSKYlun"
      },
      "source": [
        "## PyTorch tensor basics\n",
        "\n",
        "Generate PyTorch tensor with all zeros, ones or random values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2ySw3m-A9qF"
      },
      "outputs": [],
      "source": [
        "# Generate 3 x 4 tensor with all ones\n",
        "ones = torch.ones(3, 4)\n",
        "print(ones)\n",
        "\n",
        "# Generate 3 x 4 tensor with all zeros\n",
        "zeros = torch.zeros(3, 4)\n",
        "print(zeros)\n",
        "\n",
        "# Generate 3 x 4 tensor with random values on the interval [0, 1)\n",
        "random_tensor = torch.rand(3, 4)\n",
        "print(random_tensor)\n",
        "\n",
        "# Get the shape of the tensor\n",
        "print(ones.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8mp66eHBxWC"
      },
      "source": [
        "PyTorch tensors contains elements for a single data type, the `dtype`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQiOvKJJBwq4"
      },
      "outputs": [],
      "source": [
        "# Create a 3 x 4 tensor with all 32-bit floating point zeros\n",
        "zeros = torch.zeros(3, 4, dtype=torch.float32)\n",
        "print(zeros.dtype)\n",
        "\n",
        "# Change the tensor dtype to 64-bit integer\n",
        "zeros = zeros.type(torch.long)\n",
        "print(zeros.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EfegIRDkk2"
      },
      "source": [
        "## Question 5: Get the edge list of the karate club network and transform it into `torch.LongTensor`. What is the `torch.sum` value of the `pos_edge_index` tensor? (2 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEtVxMFID3ZT"
      },
      "outputs": [],
      "source": [
        "def graph_to_edge_list(G):\n",
        "  # TODO: Implement a function that returns the edge list of\n",
        "  # a nx.Graph. The returned edge_list should be a list of tuples\n",
        "  # where each tuple represents an edge between two nodes.\n",
        "\n",
        "  edge_list = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note:\n",
        "  ## Try to use simple networkx functions.\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return edge_list\n",
        "\n",
        "def edge_list_to_tensor(edge_list):\n",
        "  # TODO: Implement a function that transforms an edge_list to a\n",
        "  # tensor. The input edge_list is a list of tuples and the resulting\n",
        "  # tensor should have the shape [2 x len(edge_list)].\n",
        "\n",
        "  edge_index = torch.tensor([])\n",
        "\n",
        "  ############# Your code here ############\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return edge_index\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  pos_edge_list = graph_to_edge_list(G)\n",
        "  pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
        "  print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))\n",
        "  print(\"The pos_edge_index tensor has sum value {}\".format(torch.sum(pos_edge_index)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBL-ZmdHWqIu"
      },
      "source": [
        "## Question 6: Implement a function that samples negative edges. A negative edge exists between nodes $u$ and $v$ if there is no edge between $u$ and $v$ in the original graph.\n",
        "\n",
        "## Then, write a short function to answer which edges (edge_1 - edge_5) can be negative edges in the karate club network? (7.5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N8VT1f8-IJ8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def sample_negative_edges(G, num_neg_samples):\n",
        "  # TODO: Implement a function that returns a list of RANDOM negative edges.\n",
        "  # The number of sampled negative edges is num_neg_samples. You do not\n",
        "  # need to consider the corner case when the number of possible negative edges\n",
        "  # is less than num_neg_samples. It should be ok as long as your implementation \n",
        "  # works on the karate club network. \n",
        "  # \n",
        "  # In this implementation, self loops should not be considered as\n",
        "  # either positive or negative edge. Also, notice that \n",
        "  # the karate club network is an undirected graph; if (0, 1) is a positive \n",
        "  # edge, do you think (1, 0) can be a negative one?\n",
        "\n",
        "  # Set the random number generator seed\n",
        "  random.seed(1)\n",
        "\n",
        "  neg_edge_list = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## NOTE:\n",
        "  ## Remeber to sample negative edges randomly!\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return neg_edge_list\n",
        "\n",
        "def check_negative_edge(G, edge):\n",
        "  # TODO: Implement a function that returns whether a given edge \n",
        "  # is a negative edge within the graph G.\n",
        "\n",
        "  is_negative_edge = False\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## NOTE:\n",
        "  ## Check the definition of a negative edge from the question.\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return is_negative_edge\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  # Sample 78 negative edges\n",
        "  neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
        "\n",
        "  # Transform the negative edge list to tensor\n",
        "  neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
        "  print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n",
        "\n",
        "  # Which of following edges can be negative ones?\n",
        "  edge_1 = (7, 1)\n",
        "  edge_2 = (1, 33)\n",
        "  edge_3 = (33, 22)\n",
        "  edge_4 = (0, 4)\n",
        "  edge_5 = (4, 2)\n",
        "\n",
        "  for u, v in [edge_1, edge_2, edge_3, edge_4, edge_5]:\n",
        "    print ((u, v), check_negative_edge(G, (u, v)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9Q-a-9qGsw"
      },
      "source": [
        "# 3) Node Emebedding Learning\n",
        "\n",
        "Finally, you write your first learning algorithm on graphs: **a node embedding model**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDBxRQcZ_dUH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnqn9H6s_ehX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gomAf8vxq0R"
      },
      "source": [
        "To write your node embedding model, you will heavily utilize the [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) module in PyTorch. Let us first explore how to use `nn.Embedding`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRiWGuLAx5yx"
      },
      "outputs": [],
      "source": [
        "# Initialize an embedding layer.\n",
        "# Suppose you want to have embedding for 4 items (e.g., nodes).\n",
        "# Each item is represented by an 8 dimensional vector.\n",
        "\n",
        "emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n",
        "print('Sample embedding layer: {}'.format(emb_sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS9qQfeujEVh"
      },
      "source": [
        "You can select items from the embedding matrix by using Tensor indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AGIfP4QEDr8"
      },
      "outputs": [],
      "source": [
        "# Select an embedding in emb_sample\n",
        "id = torch.LongTensor([1])\n",
        "print(emb_sample(id))\n",
        "\n",
        "# Select multiple embeddings\n",
        "ids = torch.LongTensor([1, 3])\n",
        "print(emb_sample(ids))\n",
        "\n",
        "# Get the shape of the embedding weight matrix\n",
        "shape = emb_sample.weight.data.shape\n",
        "print(shape)\n",
        "\n",
        "# Overwrite the weight to tensor with all ones\n",
        "emb_sample.weight.data = torch.ones(shape)\n",
        "\n",
        "# Let's check if the emb is indeed initilized\n",
        "ids = torch.LongTensor([0, 3])\n",
        "print(emb_sample(ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MjBuDKaKIsM"
      },
      "source": [
        "Now, it's time to create a node embedding matrix for our graph!\n",
        "- Each node in the karate club network is represented by a **16 dimensional** vector.\n",
        "- Initalize the matrix using a **uniform distribution**, in the range of $[0, 1)$. We suggest using [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DMMHhO-iA2T"
      },
      "source": [
        "## Question 7: Implement a function creating the node embedding matrix. (2.5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMszSwRPKGn1"
      },
      "outputs": [],
      "source": [
        "# Please do not change / reset the random seed\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def create_node_emb(num_node=34, embedding_dim=16):\n",
        "  # TODO: Implement a function that creates the node embedding matrix.\n",
        "  # Return a torch.nn.Embedding layer. You do not need to change \n",
        "  # the values of num_node and embedding_dim. The weight matrix of the returned \n",
        "  # layer should be initialized using torch.rand under uniform distribution on the interval [0, 1). \n",
        "\n",
        "  emb = None\n",
        "\n",
        "  ############# Your code here ############\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return emb\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  emb = create_node_emb()\n",
        "  ids = torch.LongTensor([0, 3])\n",
        "\n",
        "  # Print the embedding layer\n",
        "  print(\"Embedding: {}\".format(emb))\n",
        "\n",
        "  # An example that gets the embeddings for node 0 and 3\n",
        "  print(emb(ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QfoANibTzyh"
      },
      "source": [
        "## Visualize the initial node embeddings\n",
        "One good way to understand an embedding matrix, is to visualize it in a 2D space.\n",
        "Here, we have implemented an embedding visualization function for you.\n",
        "We first do PCA to reduce the dimensionality of embeddings to a 2D space.\n",
        "Then, we visualize each point, colored by the community it belongs to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LCoIkarhfYD"
      },
      "outputs": [],
      "source": [
        "def visualize_emb(emb):\n",
        "  X = emb.weight.data.numpy()\n",
        "  pca = PCA(n_components=2)\n",
        "  components = pca.fit_transform(X)\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  club1_x = []\n",
        "  club1_y = []\n",
        "  club2_x = []\n",
        "  club2_y = []\n",
        "  for node in G.nodes(data=True):\n",
        "    if node[1]['club'] == 'Mr. Hi':\n",
        "      club1_x.append(components[node[0]][0])\n",
        "      club1_y.append(components[node[0]][1])\n",
        "    else:\n",
        "      club2_x.append(components[node[0]][0])\n",
        "      club2_y.append(components[node[0]][1])\n",
        "  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
        "  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the initial random embeddding\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  visualize_emb(emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQIyuEz9ANb2"
      },
      "source": [
        "## Question 8: Train your first embedding model by maximizing the dot product between positive edge node pairs and minimizng the dot product between negative edge node pairs in the graph. Through training see the best performance that you can get! You should experiment with changing a few of the hyper parameters to observe the effect on training. (10.0 Points)\n",
        "\n",
        "**NOTE**: There is no need to heavily hyper-parameter tune your model! We ask you to explore updating a couple of hyper-parameters primarily to explore their potential effects. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBo5qUVQiA2V"
      },
      "outputs": [],
      "source": [
        "class EmbModel(torch.nn.Module):\n",
        "    def __init__(self, emb):\n",
        "        # TODO: Implement the init function that initializes self.convs, \n",
        "        # self.bns, and self.softmax.\n",
        "\n",
        "        super(EmbModel, self).__init__()\n",
        "\n",
        "        # The node embedding matrix\n",
        "        self.emb = emb\n",
        "\n",
        "    def forward(self, train_edge):\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############# Your code here ############\n",
        "        ## Note:\n",
        "        # (1) Get the embeddings of the nodes in train_edge\n",
        "        # (2) Compute the embedding dot product for each node \n",
        "        # pair (positive and negative edges)\n",
        "        # (3) Feed the dot product result into sigmoid\n",
        "        ## (~5 lines of code)\n",
        "        pass\n",
        "        #########################################\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDeQTNNxqH0j"
      },
      "outputs": [],
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "def accuracy(pred, label):\n",
        "  # TODO: Implement the accuracy function. This function takes as input a \n",
        "  # pred tensor (the resulting tensor after sigmoid) and a label \n",
        "  # tensor (torch.LongTensor). Predicted values greater than 0.5 are \n",
        "  # classified as label 1, else they are classified as label 0.\n",
        "  # The returned accuracy should be rounded to 4 decimal places. \n",
        "  # For example, accuracy 0.82956 will be rounded to 0.8296.\n",
        "\n",
        "  accu = 0.0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return accu\n",
        "\n",
        "def train(model, loss_fn, sigmoid, train_label, train_edge):\n",
        "  # TODO: Train the embedding layer here. You need to implement: \n",
        "  # (1) Feed the sigmoid output into the loss_fn\n",
        "  # (2) Print both loss and accuracy of each epoch \n",
        "  # (as a sanity check, the loss should decrease during training)\n",
        "  # \n",
        "  # During testing feel free to change the number of epochs and learning rate.\n",
        "\n",
        "  epochs = 500\n",
        "  learning_rate = 0.1\n",
        "\n",
        "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    ############# Your code here ############\n",
        "    ## Note: See the training steps above!\n",
        "    pass\n",
        "    #########################################\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  loss_fn = nn.BCELoss()\n",
        "  sigmoid = nn.Sigmoid()\n",
        "\n",
        "  # Generate the positive and negative labels\n",
        "  pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "  neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "\n",
        "  # Concat positive and negative labels into one tensor\n",
        "  train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "\n",
        "  # Concat positive and negative edges into one tensor\n",
        "  # Since the network is very small, we do not split the edges into val/test sets\n",
        "  train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "  print (train_edge)\n",
        "\n",
        "  model = EmbModel(emb)\n",
        "\n",
        "  train(model, loss_fn, sigmoid, train_label, train_edge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62LuURV24Jjk"
      },
      "source": [
        "## **Saving Your Model Predictions**!\n",
        "After you have successfully trained your embedding model, run the cell below to save your model's predictions on the training data. The function below will generate and save a csv file called *model_predictions.csv* to the local Colab files folder. This folder can be accessed by clicking the *Folder* icon on the left panel underneath the *Table of contents*, *Find and replace*, and *Code snippets* icons. \n",
        "\n",
        "When submitting this Colab you will have to download your model's predictions and submit them along with your Colab ipython notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Jjz5J1W4GLj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def save_model_results(emb_model, train_label, train_edge):\n",
        "  \"\"\"\n",
        "    Helper function to save the model predictions and data\n",
        "    labels to a csv file for submission.\n",
        "  \"\"\"\n",
        "\n",
        "  # Generate model predictions\n",
        "  pred = emb_model(train_edge).detach()\n",
        "\n",
        "  # Create a pandas datafram with columns\n",
        "  # model_pred | binary_pred | label\n",
        "  data = {}\n",
        "  data['model_pred'] = pred\n",
        "  data['binary_pred'] = np.where(pred > 0.5, 1.0, 0.0)\n",
        "  data['label'] = train_label.detach()\n",
        "\n",
        "  df = pd.DataFrame(data=data)\n",
        "  # Save to csv\n",
        "  df.to_csv('model_predictions.csv', sep=',', index=False)\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  save_model_results(model, train_label, train_edge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX2PSXnTDiNi"
      },
      "source": [
        "## Visualize the final node embeddings\n",
        "Now you can visually compare our embeddings with the embeddings before training. After training, you should oberserve that the two classes are more evidently separated. Note that since we are reducing the dimensionality of our embeddings from **16 --> 2** you may not see perfect linear sepeartion.\n",
        "\n",
        "\n",
        "Overall, visualizing model / node embeddings is a great sanity check for your implementation, in addition to tracking the model's accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtNgl4VhYKow"
      },
      "outputs": [],
      "source": [
        "# Visualize the final learned embedding\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  visualize_emb(emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTNyrAoSVeq9"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_E7J_GkVhY_"
      },
      "source": [
        "You will need to submit two files on Gradescope to complete this notebook. \n",
        "\n",
        "1.   Your completed *XCS224W_Colab1.ipynb*. From the \"File\" menu select \"Download .ipynb\" to save a local copy of your completed Colab. \n",
        "2.   Your model predictions. Open up the local Colab file folder (by selecting the Folder icon on the left panel) and download *model_predictions.csv* \n",
        "\n",
        "For submitting your work, zip the files downloaded in steps 1 and 2 above and submit to gradescope. **NOTE:** DO NOT rename any of the downloaded files. The file names should be *XCS224W_Colab1.ipynb* and *model_predictions.csv*.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "XCS224W_Colab1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}